{"componentChunkName":"component---src-templates-blog-post-js","path":"/word-vector/2017-07-19-word-vector-pt-1/","webpackCompilationHash":"45521898074de96503d4","result":{"data":{"site":{"siteMetadata":{"title":"MatthewReishus.com","author":"Matthew Reishus"}},"markdownRemark":{"id":"26e2bba4-d174-59a1-90b3-7308751bff75","excerpt":"Intro to Part 1 In this series, I’ll be showing how to use an off-the-shelf model mapping english words to\nvectors in your own programs.   We’ll start with a…","html":"<h1>Intro to Part 1</h1>\n<p>In this series, I’ll be showing how to use an off-the-shelf model mapping english words to\nvectors in your own programs.   We’ll start with a simple react application searching a dataset,\nthen use the word vector model to enhance the search.  We want to search for more than the exact\nword the user types.  For example, if I type <code class=\"language-text\">sailing</code>, perhaps we will match the words <code class=\"language-text\">boat</code>,\n<code class=\"language-text\">yacht</code>, etc.</p>\n<h1>What is a word vector?</h1>\n<p>It’s a technique used in machine learning where words are translated into a vector space.\nYou might also see it referred to as an <code class=\"language-text\">embedding</code>.  There are a few different techniques to generate these\nmappings, but that’s not the focus of this blog series.  We’ll simply be downloading a well-known\npre-trained model and use it in our application: <a href=\"https://code.google.com/archive/p/word2vec/\">GoogleNews-vectors-negative300.bin.gz</a>.</p>\n<p>This one was trained off of 100 billion words from google news and is a few years old at this point.\nYou can find many other pretrained models, some generated with different techniques online;\nhowever, I’ve had excellent results using this one.</p>\n<p>Each word is encoded as a vector in 300 dimensions.  For example, the word <code class=\"language-text\">chair</code> is represented by this array:\n<code class=\"language-text\">[0.118652, -0.375000, 0.161133, 0.002151, ...295 numbers omitted.. , 0.171875]</code>.  One interesting feature is\nthat some intuitive concepts might be embedded in simple linear transformations.  For example, perhaps adding\n<code class=\"language-text\">[0.5, 0.3, 0.6, 0, 0, 0, 0, 0....]</code> to the vector for <code class=\"language-text\">man</code> ends up being the vector for <code class=\"language-text\">woman</code>, and adding it\nto <code class=\"language-text\">king</code> gets you <code class=\"language-text\">queen</code>.  This is simplifying a bit, the <code class=\"language-text\">male-&gt;female</code> vector is not as clean as my example,\nbut it’s still a very neat result.  Here’s a graphic from google showing some linear relationships:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b1735761f02a7cb51e8835cf0a8d77d3/9910f/wordvec-linear-relationships.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.01661129568106%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsSAAALEgHS3X78AAAA7ElEQVQY02VQbW/GIAjs//+PNlnzfJotKorga0fXpGk2QhDRuyO3nOc55zz/RWvtzwRD8Ei5dikjszDzolM9WEpr/f01Z0bnaikPe0RMxJ5qoAohOQdL68P75FGZGhPnnH+xI5NjsGNMzZtORIiy1MGlZy6ZaFHR/UAEjBAR4rziRDx2u11LgUUAbXrvzjkkUVkXxR4upbTUWhOlFAlACVChY4wY9YmtNSlAEbmVvXf28C4VzW97kCor+DHsbm68VmZ6dr7EW1Nz+jhbn1KKAi/DPp+PMUbrm2Lfd2PWEMLbxRjjtn2t62qt1esPdImWVI18LPIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Wordvec linear relationships\"\n        title=\"Wordvec linear relationships\"\n        src=\"/static/b1735761f02a7cb51e8835cf0a8d77d3/b9e4f/wordvec-linear-relationships.png\"\n        srcset=\"/static/b1735761f02a7cb51e8835cf0a8d77d3/cf440/wordvec-linear-relationships.png 148w,\n/static/b1735761f02a7cb51e8835cf0a8d77d3/d2d38/wordvec-linear-relationships.png 295w,\n/static/b1735761f02a7cb51e8835cf0a8d77d3/b9e4f/wordvec-linear-relationships.png 590w,\n/static/b1735761f02a7cb51e8835cf0a8d77d3/f9b6a/wordvec-linear-relationships.png 885w,\n/static/b1735761f02a7cb51e8835cf0a8d77d3/2d849/wordvec-linear-relationships.png 1180w,\n/static/b1735761f02a7cb51e8835cf0a8d77d3/9910f/wordvec-linear-relationships.png 1505w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </a>\n    </span></p>\n<p>I’ve explored this feature some.  I’ve found it to be impressive but a bit messy and not as clean as the diagrams.\nI haven’t found any practical use for it. (Analogy completer?)</p>\n<h1>Starting point: A simple app without any word vectors</h1>\n<p>Let’s start with a simple react app that loads a dataset in memory and lets you type to search it.<br>\nI made a quick one that searches a list of all S&#x26;P 500 companies and their descriptions.</p>\n<p><a href=\"/vector-apps/part1/\">Here is the app</a>.\n<a href=\"https://github.com/mreishus/vector-search-example/tree/02_lunr_search/front-end\">Here is the source code</a>.</p>\n<p>I made it quickly using <code class=\"language-text\">create-react-app</code>.  The CSS classes are from <a href=\"http://tachyons.io/\">tachyons</a> - they will\nlook weird if you’ve never seen them before.  It uses <a href=\"https://lunrjs.com/\">lunrjs</a> to search.</p>\n<h1>Up Next</h1>\n<p>Next, we will start building a related words service using the <a href=\"https://code.google.com/archive/p/word2vec/\">GoogleNews-vectors-negative300.bin.gz</a> model and make the app use it.</p>","frontmatter":{"title":"Word Vector Series: Part 1 - Intro","date":"July 20, 2017","description":null}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/word-vector/2017-07-19-word-vector-pt-1/","previous":null,"next":{"fields":{"slug":"/word-vector/2017-07-21-word-vector-pt-2/"},"frontmatter":{"title":"Word Vector Series: Part 2 - Downloading the model","templateKey":"blog-post"}}}}}