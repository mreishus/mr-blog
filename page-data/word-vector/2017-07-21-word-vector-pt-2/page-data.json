{"componentChunkName":"component---src-templates-blog-post-js","path":"/word-vector/2017-07-21-word-vector-pt-2/","result":{"data":{"site":{"siteMetadata":{"title":"MatthewReishus.com"}},"markdownRemark":{"id":"400e9d30-bb94-56ad-9300-a9d4fdcfe20f","excerpt":"Intro to Part 2 In part 2, we’ll be downloading the model and trimming it to a reasonable size. Previous: Part 1 \nNext: Part 3 Downloading the model Download…","html":"<h1>Intro to Part 2</h1>\n<p>In part 2, we’ll be downloading the model and trimming it to a reasonable size.</p>\n<!--more-->\n<p>Previous: <a href=\"/word-vector/2017-07-19-word-vector-pt-1\">Part 1</a> <br />\nNext: <a href=\"/word-vector/2017-07-21-word-vector-pt-3\">Part 3</a></p>\n<h1>Downloading the model</h1>\n<p>Download GoogleNews-vectors-negative300.bin.gz from either\n<a href=\"https://code.google.com/archive/p/word2vec/\">code.google.com</a> (requires a browser, ctrl-f negative300)\nor <a href=\"https://github.com/mmihaltz/word2vec-GoogleNews-vectors\">this github archive</a> (requires git-lfs).</p>\n<p>Unzip the file with gzip.  It’s quite large and in a binary format made for a python library called word2vec.  I’d\nlike to make the service in nodejs, so let’s convert it to text.  We can use a program called <a href=\"https://github.com/marekrei/convertvec\">convertvec</a> to do this. An actual command list looks something like:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ git clone git@github.com:marekrei/convertvec.git\n$ cd convertvec\n$ make\n$ cp convertvec ../cv\n$ cd ..\n$ chmod +x cv\n$ ./cv bin2txt GoogleNews-vectors-negative300.bin GoogleNews-vectors-negative300.txt\n$ rm -rf convertvec</code></pre></div>\n<p>Now you should have <code class=\"language-text\">GoogleNews-vectors-negative300.txt</code>.  It’s huge - 8 gigs - and contains 3 million lines (words).\nThe format looks like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">in 0.070312 0.086914 0.087891 0.062500 0.069336 -0.108887 -0.081543 -0.154297 0.020752 0.131836 -0.113770 -0.037354 0.069336 0.078125 -0.103027 -0.097656 0.044189 0.102539 -0.060791 -0.036133 -0.045410 0.047363 -0.120605 -0.063965 0.002258 0.037109 -0.002914 0.117676 0.061768 0.063965 0.081055 -0.068848 -0.021362 0.055176 -0.085449 0.068848 -0.127930 -0.033203 0.098633 0.175781 0.110840 -0.034668 -0.047119 -0.008484 0.035889 0.103027 0.026978 -0.028687 -0.005127 0.106445 0.059814 0.094238 0.033691 -0.027100 -0.094238 0.001030 -0.048340 0.034424 0.081055 -0.113281 -0.088867 0.035889 -0.145508 -0.244141 -0.061523 0.052979 0.056885 0.179688 0.061035 0.086914 0.124023 -0.040283 0.022583 0.177734 -0.029663 -0.029663 0.117188 0.031128 -0.096191 0.066406 0.004700 -0.080078 0.062988 -0.020630 -0.054688 -0.135742 -0.063477 0.083496 -0.063965 0.021484 0.077148 -0.037109 -0.033691 -0.183594 -0.072754 0.015869 0.093262 -0.061523 -0.014221 -0.003448 0.011108 -0.158203 -0.017090 0.006195 -0.008728 -0.080566 -0.015259 -0.087891 0.003479 -0.016113 -0.012329 0.097656 -0.139648 -0.085938 -0.026855 0.053955 0.132812 0.112793 0.121094 0.085449 -0.007111 0.044678 -0.145508 -0.003204 -0.117676 -0.065430 0.071289 -0.094238 -0.030273 0.120117 0.080078 -0.094727 -0.162109 -0.077637 0.021240 -0.081543 0.003937 -0.157227 -0.098145 0.039795 0.039307 -0.009094 0.103027 0.067871 -0.042725 0.063477 -0.049072 0.020874 -0.166992 0.093262 0.093750 0.006866 0.053711 0.052490 -0.024414 -0.032471 -0.061523 -0.005554 0.096191 0.037842 0.012207 -0.043945 -0.007477 0.105469 0.020386 0.145508 0.082031 0.005768 0.004578 -0.092773 -0.138672 -0.057373 -0.051514 -0.130859 -0.139648 -0.020508 -0.027100 0.032715 0.104980 -0.002335 -0.022583 0.000504 -0.110840 0.084961 -0.129883 -0.017456 -0.000359 0.107910 0.088867 0.044678 0.025146 0.023804 0.081055 0.023682 -0.109863 0.005371 -0.017700 -0.033936 -0.032959 -0.164062 0.095703 -0.018311 0.005310 -0.034424 -0.044189 -0.066406 -0.017944 -0.029663 -0.007599 -0.051270 -0.054199 0.089355 -0.071777 0.015259 -0.082520 -0.031738 0.035645 -0.021240 -0.059326 -0.013062 0.046875 0.023071 0.020996 -0.078613 -0.008057 0.019531 -0.005554 0.041504 0.027832 0.013611 0.034668 -0.182617 0.120117 0.074219 -0.041016 -0.009949 0.042969 -0.007294 0.123047 0.057617 -0.053467 -0.032227 -0.009094 -0.046631 0.043945 -0.050781 0.068848 0.002991 -0.004181 -0.044189 0.073730 -0.012756 0.067383 0.006287 0.075195 -0.037842 0.004883 0.044678 -0.067383 0.009705 0.004730 0.020508 0.071289 0.170898 0.173828 0.055664 0.091309 -0.037354 0.049805 -0.039307 0.044189 0.062500 0.048584 -0.053223 0.048828 -0.130859 -0.028931 -0.036133 -0.060791 -0.057373 0.123047 -0.082520 -0.011902 0.125000 0.001358 0.063965 -0.106445 -0.143555 -0.042236 0.024048 -0.168945 -0.088867 -0.080566 0.064941 0.061279 -0.047363 -0.058838 -0.047607 0.014465 -0.062500 </code></pre></div>\n<p>I’d like to make a simple service that has a smallish resource footprint, so let’s not load the whole thing.<br>\nThe words at sorted by popularity.  At the top of the file we have <code class=\"language-text\">&lt;/s&gt;</code>, <code class=\"language-text\">in</code>, <code class=\"language-text\">for</code>, and <code class=\"language-text\">that</code>;\nat the bottom, we have <code class=\"language-text\">Mezze_Cafe</code>, <code class=\"language-text\">pulverizes_boulders</code>, and <code class=\"language-text\">snowcapped_Caucasus</code>.</p>\n<p>Some things to notice:  The model uses capital letters sometimes, it contains compound phrases separated by\nunderscores, and there are some special codes.  Our implementation will only look up single words for simplicity, but\nwe need to make sure to take care of capitalization:  the user could type <code class=\"language-text\">monday</code> but the model only contains <code class=\"language-text\">Monday</code>.</p>\n<h1>Trimming the model</h1>\n<p>So let’s cut off a section of the top of the file and convert it to a javascript object.  I wrote a quick\nruby program to do this (it won’t win any awards!):</p>\n<div class=\"gatsby-highlight\" data-language=\"ruby\"><pre class=\"language-ruby\"><code class=\"language-ruby\"><span class=\"token comment\">#!env ruby</span>\n<span class=\"token keyword\">require</span> <span class=\"token string\">'json'</span>\n\ninput_array <span class=\"token operator\">=</span> <span class=\"token constant\">ARGV</span>\n<span class=\"token keyword\">if</span> input_array<span class=\"token punctuation\">.</span>length <span class=\"token operator\">&lt;</span> <span class=\"token number\">1</span>\n  puts <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token delimiter tag\">#{</span>$<span class=\"token number\">0</span><span class=\"token delimiter tag\">}</span></span>: How many words should I include in the model?\"</span>\n  puts <span class=\"token string\">\"Use \\\"./<span class=\"token interpolation\"><span class=\"token delimiter tag\">#{</span>$<span class=\"token number\">0</span><span class=\"token delimiter tag\">}</span></span> 10000\\\" to make a 10,000 word model.\"</span>\n  exit\n<span class=\"token keyword\">end</span>\n\nlimit <span class=\"token operator\">=</span> <span class=\"token constant\">ARGV</span><span class=\"token punctuation\">.</span>shift\n<span class=\"token keyword\">if</span> <span class=\"token operator\">!</span><span class=\"token punctuation\">(</span>limit <span class=\"token operator\">=</span><span class=\"token operator\">~</span> <span class=\"token regex\">/\\A\\d+\\Z/</span><span class=\"token punctuation\">)</span>\n  puts <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token delimiter tag\">#{</span>$<span class=\"token number\">0</span><span class=\"token delimiter tag\">}</span></span>: Please provide a limit in numbers.\"</span>\n  puts <span class=\"token string\">\"Use \\\"./<span class=\"token interpolation\"><span class=\"token delimiter tag\">#{</span>$<span class=\"token number\">0</span><span class=\"token delimiter tag\">}</span></span> 10000\\\" to make a 10,000 word model.\"</span>\n  exit\n<span class=\"token keyword\">end</span>\nlimit <span class=\"token operator\">=</span> limit<span class=\"token punctuation\">.</span>to_i\n\nputs <span class=\"token string\">\"module.exports = {\"</span>\nwords_seen <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\noutput_index <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token builtin\">File</span><span class=\"token punctuation\">.</span>open<span class=\"token punctuation\">(</span><span class=\"token string\">\"./GoogleNews-vectors-negative300.txt\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"r\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">do</span> <span class=\"token operator\">|</span>file<span class=\"token operator\">|</span>\n  file<span class=\"token punctuation\">.</span>each_with_index <span class=\"token keyword\">do</span> <span class=\"token operator\">|</span>line<span class=\"token punctuation\">,</span> input_index<span class=\"token operator\">|</span>\n\n    <span class=\"token keyword\">next</span> <span class=\"token keyword\">if</span> input_index <span class=\"token operator\">==</span> <span class=\"token number\">0</span>\n    line_array <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>split\n    word <span class=\"token operator\">=</span> line_array<span class=\"token punctuation\">.</span>shift<span class=\"token punctuation\">.</span>downcase\n\n    <span class=\"token keyword\">next</span> <span class=\"token keyword\">if</span> words_seen<span class=\"token punctuation\">.</span>key<span class=\"token operator\">?</span><span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n    words_seen<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n\n    vectorPart <span class=\"token operator\">=</span> line_array<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token string\">\", \"</span><span class=\"token punctuation\">)</span>\n\n    puts <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token delimiter tag\">#{</span><span class=\"token constant\">JSON</span><span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span><span class=\"token delimiter tag\">}</span></span>: [<span class=\"token interpolation\"><span class=\"token delimiter tag\">#{</span>vectorPart<span class=\"token delimiter tag\">}</span></span>],\"</span>\n    output_index <span class=\"token operator\">+</span><span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">break</span> <span class=\"token keyword\">if</span> output_index <span class=\"token operator\">>=</span> limit\n  <span class=\"token keyword\">end</span>\n<span class=\"token keyword\">end</span>\nputs <span class=\"token string\">\"};\"</span></code></pre></div>\n<p>Use it like so: <code class=\"language-text\">$ ./make_model.rb 25000 &gt; ../words25k.js</code></p>\n<p>A 25k word model is about 75 megabytes, and includes a reasonable number of words.  Here’s a graph showing\nestimated vocabulary size for English native speakers from <a href=\"http://testyourvocab.com/\">testyourvocab.com</a>:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/81952aa53e57f10e3403a6457b690e14/0c9cf/vocab1.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.432432432432435%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHcLwKHB//EABYQAAMAAAAAAAAAAAAAAAAAABARIP/aAAgBAQABBQIOP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABwQAAICAgMAAAAAAAAAAAAAAAABESExQVFxkf/aAAgBAQABPyF3pPshrEeCpsYiFwf/2gAMAwEAAgADAAAAEIMP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHRAAAQQCAwAAAAAAAAAAAAAAAQARIVExQRBhkf/aAAgBAQABPxAGhzLDCE4BtmLaPBLZza6Hi//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Vocab graph\"\n        title=\"Vocab graph\"\n        src=\"/static/81952aa53e57f10e3403a6457b690e14/1c72d/vocab1.jpg\"\n        srcset=\"/static/81952aa53e57f10e3403a6457b690e14/a80bd/vocab1.jpg 148w,\n/static/81952aa53e57f10e3403a6457b690e14/1c91a/vocab1.jpg 295w,\n/static/81952aa53e57f10e3403a6457b690e14/1c72d/vocab1.jpg 590w,\n/static/81952aa53e57f10e3403a6457b690e14/0c9cf/vocab1.jpg 613w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1>Up next</h1>\n<p>In part 3, we’ll be using some basic linear algebra to find related words.</p>\n<p>Previous: <a href=\"/word-vector/2017-07-19-word-vector-pt-1\">Part 1</a> <br />\nNext: <a href=\"/word-vector/2017-07-21-word-vector-pt-3\">Part 3</a></p>","frontmatter":{"title":"Word Vector Series: Part 2 - Downloading the model","date":"July 21, 2017","description":null}}},"pageContext":{"slug":"/word-vector/2017-07-21-word-vector-pt-2/","previous":{"fields":{"slug":"/word-vector/2017-07-19-word-vector-pt-1/"},"frontmatter":{"title":"Word Vector Series: Part 1 - Intro","templateKey":"blog-post"}},"next":{"fields":{"slug":"/word-vector/2017-07-21-word-vector-pt-3/"},"frontmatter":{"title":"Word Vector Series: Part 3 - Creating a similar word service","templateKey":"blog-post"}}}}}